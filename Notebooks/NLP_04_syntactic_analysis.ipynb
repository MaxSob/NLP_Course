{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Syntactic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Syntactic analysis in NLP deals with the correct formation of the text. Usually deals with the concept of parsing study at the level of how sentences are formed with respect to a grammar and it's structure. This level of linguistic processing utilizes a parsers to extract the structure fo the phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Free Grammars\n",
    "Context free grammars are a powerful generation tool which allow us to represent a wide variety of free ontext languages which are impossible to express using regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple grammar to represent the language : <img src=\"https://latex.codecogs.com/gif.latex?O^n1^n\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.draw.tree import draw_trees\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Z A | eps \n",
    "A -> B O | '1'\n",
    "B -> Z A\n",
    "Z -> '0'\n",
    "O -> '1'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (Z 0) (A (B (Z 0) (A (B (Z 0) (A 1)) (O 1))) (O 1)))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar)\n",
    "phrase = ['0', '0', '0', '1', '1', '1']\n",
    "for tree in parser.parse(phrase):\n",
    "    print(tree)\n",
    "    draw_trees(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Design a grammar to recognize the language <img src=\"https://latex.codecogs.com/gif.latex?${a^{i}b^{j}c^{k} | i, j, k \\geq 0, i = k$\" /> test it using the strings aaabbbc, aaabccc and aabbbbccc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushdown automata\n",
    "A pushdown automata is a theoreticla machine which can model free context grammars. It's matematical definition is confomed bya 6 tuple which includes the following elements:\n",
    "* Q: Set of the states of the automata\n",
    "* Sigma: Set of input symbols\n",
    "* Gamma: set of stack symbols\n",
    "* Delta: transition function\n",
    "* F: set of acceptance states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonando en 'SimplePushdownAutomata'...\n",
      "remote: Enumerating objects: 22, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 22 (delta 8), reused 16 (delta 6), pack-reused 0\n",
      "Desempaquetando objetos: 100% (22/22), listo.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MaxSob/SimplePushdownAutomata.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from PushdownAutomata import PushdownAutomata\n",
      "\n",
      "#Automata definition\n",
      "q = ['q1','q2','q3','q4']\n",
      "sigma = ['0','1']\n",
      "gamma = ['0',\"$\"]\n",
      "delta = {}\n",
      "f = ['q1','q4']\n",
      "\n",
      "#Rule definition\n",
      "a = PushdownAutomata(q, sigma, gamma, delta, 'q1', f)\n",
      "a.addRule('q1','q2','epsilon','epsilon','$')\n",
      "a.addRule('q2','q2','0', 'epsilon', '0')\n",
      "a.addRule('q2','q3','1', '0', 'epsilon')\n",
      "a.addRule('q3','q3','1', '0', 'epsilon')\n",
      "a.addRule('q3','q4','epsilon', '$', 'epsilon')\n",
      "\n",
      "#Process a String\n",
      "accepted_paths = a.processInput('000111')\n",
      "a.printPaths(accepted_paths)\n"
     ]
    }
   ],
   "source": [
    "!more ./SimplePushdownAutomata/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the automata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(None, 'q1', [])]]\n",
      "******************************\n",
      "Processing char 1 : 0\n",
      "q1 [] 0\n",
      "Applying q1: (epsilon,epsilon)-->$ : q2\n",
      "Applying q2: (0,epsilon)-->0 : q2\n",
      "******************************\n",
      "Processing char 2 : 0\n",
      "q2 ['$', '0'] 0\n",
      "Applying q2: (0,epsilon)-->0 : q2\n",
      "******************************\n",
      "Processing char 3 : 0\n",
      "q2 ['$', '0', '0'] 0\n",
      "Applying q2: (0,epsilon)-->0 : q2\n",
      "******************************\n",
      "Processing char 4 : 1\n",
      "q2 ['$', '0', '0', '0'] 1\n",
      "Applying q2: (1,0)-->epsilon : q3\n",
      "******************************\n",
      "Processing char 5 : 1\n",
      "q3 ['$', '0', '0'] 1\n",
      "Applying q3: (1,0)-->epsilon : q3\n",
      "******************************\n",
      "Processing char 6 : 1\n",
      "q3 ['$', '0'] 1\n",
      "Applying q3: (1,0)-->epsilon : q3\n",
      "Applying q3: (epsilon,$)-->epsilon : q4\n",
      "Printing path: 1\n",
      "None\n",
      "q1: (epsilon,epsilon)-->$ : q2\n",
      "q2: (0,epsilon)-->0 : q2\n",
      "q2: (0,epsilon)-->0 : q2\n",
      "q2: (0,epsilon)-->0 : q2\n",
      "q2: (1,0)-->epsilon : q3\n",
      "q3: (1,0)-->epsilon : q3\n",
      "q3: (1,0)-->epsilon : q3\n",
      "q3: (epsilon,$)-->epsilon : q4\n"
     ]
    }
   ],
   "source": [
    "!python ./SimplePushdownAutomata/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CYK algorithm\n",
    "**Exercise:** implement a simple CYK algorithm like https://github.com/RobMcH/CYK-Parser/blob/master/cyk_parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CYK(rules, string):\n",
    "    table = []\n",
    "    #Your code here\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see another example with an ambiguous grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grammar permits the sentence to be analyzed in two ways, depending on whether the prepositional phrase in my pajamas describes the elephant or the shooting event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/NLP_04_syntactic_analysis_tree_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/NLP_04_syntactic_analysis_tree_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    draw_trees(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive descent parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest kind of parser interprets a grammar as a specification of how to break a high-level goal into several lower-level subgoals. The top-level goal is to find an S. The S â†’ NP VP production permits the parser to replace this goal with two subgoals: find an NP, then find a VP. Each of these subgoals can be replaced in turn by sub-sub-goals, using productions that have NP and VP on their left-hand side. Eventually, this expansion process leads to subgoals such as: find the word telescope. Such subgoals can be directly compared against the input sequence, and succeed if the next word is matched. If there is no match the parser must back up and try a different alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing revursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)\n",
    "    draw_trees(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive descent parsing has three key shortcomings. First, left-recursive productions like NP -> NP PP send it into an infinite loop. Second, the parser wastes a lot of time considering words and structures that do not correspond to the input sentence. Third, the backtracking process may discard parsed constituents that will need to be rebuilt again later. For example, backtracking over VP -> V NP will discard the subtree created for the NP. If the parser then proceeds with VP -> V NP PP, then the NP subtree must be created all over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift reduce parser\n",
    "A simple kind of bottom-up parser is the shift-reduce parser. In common with all bottom-up parsers, a shift-reduce parser tries to find sequences of words and phrases that correspond to the right hand side of a grammar production, and replace them with the left-hand side, until the whole sentence is reduced to an S.\n",
    "\n",
    "The shift-reduce parser repeatedly pushes the next input word onto a stack; this is the shift operation. If the top n items on the stack match the n items on the right hand side of some production, then they are all popped off the stack, and the item on the left-hand side of the production is pushed on the stack. This replacement of the top n items with a single item is the reduce operation. This operation may only be applied to the top of the stack; reducing items lower in the stack must be done before later items are pushed onto the stack. The parser finishes when all the input is consumed and there is only one item remaining on the stack, a parse tree with an S node as its root. The shift-reduce parser builds a parse tree during the above process. Each time it pops n items off the stack it combines them into a partial parse tree, and pushes this back on the stack. We can see the shift-reduce parsing algorithm in action using the graphical demonstration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.app.srparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the shift reduce parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)\n",
    "    draw_trees(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A shift-reduce parser can reach a dead end and fail to find any parse, even if the input sentence is well-formed according to the grammar. When this happens, no input remains, and the stack contains items which cannot be reduced to an S. The problem arises because there are choices made earlier that cannot be undone by the parser (although users of the graphical demonstration can undo their choices). There are two kinds of choices to be made by the parser: (a) which reduction to do when more than one is possible (b) whether to shift or reduce when either action is possible.\n",
    "\n",
    "The advantage of shift-reduce parsers over recursive descent parsers is that they only build structure that corresponds to the words in the input. Furthermore, they only build each sub-structure once, e.g.  NP(Det(the), N(man)) is only built and pushed onto the stack a single time, regardless of whether it will later be used by the VP -> V NP PP reduction or the NP -> NP PP reduction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
